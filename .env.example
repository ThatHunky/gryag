TELEGRAM_TOKEN=
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.5-flash
GEMINI_EMBED_MODEL=models/text-embedding-004
DB_PATH=./gryag.db
MAX_TURNS=50
CONTEXT_SUMMARY_THRESHOLD=30
PER_USER_PER_HOUR=5
USE_REDIS=false
REDIS_URL=redis://localhost:6379/0
ADMIN_USER_IDS=
RETENTION_DAYS=30
ENABLE_SEARCH_GROUNDING=false

# Weather API (OpenWeatherMap)
OPENWEATHER_API_KEY=
OPENWEATHER_BASE_URL=https://api.openweathermap.org/data/2.5

# Currency API (ExchangeRate-API) 
EXCHANGE_RATE_API_KEY=
EXCHANGE_RATE_BASE_URL=https://v6.exchangerate-api.com

# User Profiling
ENABLE_USER_PROFILING=true
USER_PROFILE_RETENTION_DAYS=365
MAX_FACTS_PER_USER=100
FACT_CONFIDENCE_THRESHOLD=0.7
FACT_EXTRACTION_ENABLED=true
PROFILE_SUMMARIZATION_INTERVAL_HOURS=24
MIN_MESSAGES_FOR_EXTRACTION=5

# Profile Summarization (Phase 2)
# Background task that generates summaries of user profiles
# Optimized for i5-6500: processes 1 profile at a time, runs at 3 AM
ENABLE_PROFILE_SUMMARIZATION=false
PROFILE_SUMMARIZATION_HOUR=3
PROFILE_SUMMARIZATION_BATCH_SIZE=30
MAX_PROFILES_PER_DAY=50

# Fact Extraction Method (rule_based, local_model, hybrid, gemini)
# - rule_based: Fast regex patterns (instant, 70% coverage, zero cost)
# - local_model: Local LLM inference (100-500ms, 85% coverage, requires model)
# - hybrid: Rule-based + local model + optional Gemini fallback (recommended)
# - gemini: Legacy Gemini-only mode (not recommended)
FACT_EXTRACTION_METHOD=hybrid

# Local Model Configuration (required for local_model or hybrid modes)
# Download model with: bash download_model.sh
# Or manually: wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf -O models/phi-3-mini-q4.gguf
LOCAL_MODEL_PATH=models/phi-3-mini-q4.gguf
LOCAL_MODEL_THREADS=4

# Gemini Fallback (optional, disabled by default)
# Only used in hybrid mode when rule-based and local model find <2 facts
ENABLE_GEMINI_FALLBACK=false

# Continuous Learning System (Phase 1+)
# Intelligent continuous monitoring that learns from all messages
ENABLE_CONTINUOUS_MONITORING=true
ENABLE_MESSAGE_FILTERING=false          # Phase 3: Start filtering low-value messages
ENABLE_ASYNC_PROCESSING=false           # Phase 3: Enable async fact extraction

# Conversation Window Settings
# Groups messages into windows for better context understanding
CONVERSATION_WINDOW_SIZE=8              # Messages per window (3-20)
CONVERSATION_WINDOW_TIMEOUT=180         # Seconds before window closes (60-600)
MAX_CONCURRENT_WINDOWS=100              # Max windows tracked simultaneously

# Event Queue Settings
# Async processing with priority queue and circuit breakers
MONITORING_WORKERS=3                    # Number of async workers (1-10)
MAX_QUEUE_SIZE=1000                     # Max queued events (100-10000)
ENABLE_CIRCUIT_BREAKER=true             # Fault tolerance
CIRCUIT_BREAKER_THRESHOLD=5             # Failures before opening circuit (3-20)
CIRCUIT_BREAKER_TIMEOUT=60              # Seconds before retry (30-300)

# Proactive Response Settings (Phase 4)
# Bot proactively joins conversations when it can help
ENABLE_PROACTIVE_RESPONSES=false        # Phase 4: Enable proactive engagement
PROACTIVE_CONFIDENCE_THRESHOLD=0.75     # Minimum confidence to respond (0.5-1.0)
PROACTIVE_COOLDOWN_SECONDS=300          # Min seconds between proactive responses

# System Health Monitoring
ENABLE_HEALTH_METRICS=true              # Track system health
HEALTH_CHECK_INTERVAL=300               # Seconds between health checks


