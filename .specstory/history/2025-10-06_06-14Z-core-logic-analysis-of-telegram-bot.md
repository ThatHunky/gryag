<!-- Generated by SpecStory -->

<!-- vscode Session 56b22972-246d-4c14-85c9-3d37bec30bf0 (2025-10-06 06:14Z) -->

# Core logic analysis of Telegram bot (2025-10-06 06:14Z)

_**User (2025-10-06 06:15Z)**_

Check the codebase and tell me the core logics of the bot

---

_**Assistant (copilot/claude-sonnet-4.5)**_

I'll analyze the codebase to understand the core logic of this Telegram bot. Let me start by examining the key files. 

Now let me examine a few more key components to complete the picture: 

Based on my analysis of the codebase, here are the **core logic components** of this Telegram bot:

## **Core Bot Logic**

### **1. Entry Point & Architecture** (`main.py`)
- **Framework**: Uses aiogram v3 for Telegram bot operations
- **Startup Flow**:
  1. Initializes all services (database, Gemini AI, user profiling, monitoring)
  2. Sets up middleware pipeline (metadata injection → throttling)
  3. Registers routers for chat, admin, and profile management
  4. Starts long-polling with pending update purging
  5. Runs background resource monitoring task

### **2. Message Processing Pipeline** (`chat.py`)

**Flow for every incoming message**:
1. **Initial filtering**: Ignore bots, log telemetry
2. **Continuous monitoring**: Process ALL messages for learning/profiling (Phase 1+)
3. **Address detection**: Check if bot is explicitly mentioned/replied to
4. **Context caching**: Store unaddressed messages for potential context
5. **Throttling check**: Admins bypass, others rate-limited
6. **Ban check**: Reject banned users
7. **History retrieval**: Get recent conversation (max 50 turns, summarized if >30)
8. **Media processing**: Extract photos, documents, stickers as base64
9. **User profiling**: Enrich context with stored user facts
10. **Gemini generation**: Call AI with system persona + tools + history
11. **Tool execution**: Handle calculator, weather, currency, polls, semantic search
12. **Response cleanup**: Strip metadata leakage, escape Markdown
13. **Storage**: Persist user turn + bot response with embeddings

### **3. AI Integration** (`gemini.py`)

**GeminiClient** handles:
- **Text generation** with system instructions, conversation history, and tool definitions
- **Circuit breaker**: Auto-cooldown after 3 failures (60s timeout)
- **Tool calling**: Multi-round function execution (search, calculator, weather, currency, polls)
- **Embeddings**: Rate-limited (8 concurrent) for semantic similarity
- **Fallback logic**: Retries without tools if API rejects them
- **Safety**: Blocks no harmful content (all categories set to `BLOCK_NONE`)

### **4. Persona & Behavior** (`persona.py`)

The bot is **gryag** - a sarcastic Ukrainian guy who:
- Talks in colloquial Ukrainian with profanity
- Never reveals being a bot or shows technical metadata
- Has strong pro-Ukraine stance, mocks russia
- Uses plain text only (no markdown formatting)
- Has special relationships with admin `кавунева пітса` and creator `батько`
- Knowledge cutoff: mid-2024

### **5. Persistence Layer** (`context_store.py`)

**SQLite database** (`gryag.db`) stores:
- **messages**: Full conversation history with embeddings for semantic search
- **quotas**: Rate limit tracking per user/chat
- **bans**: Banned user list
- **notices**: Cooldowns for error messages

**Key features**:
- Cosine similarity search across message embeddings
- Auto-pruning old data based on retention days
- Thread-aware history retrieval
- Metadata formatting for Gemini context

### **6. Middleware Stack**

**ChatMetaMiddleware**: Injects dependencies into every handler
- Bot identity, settings, context store, Gemini client
- User profiling, fact extraction, continuous monitoring
- Optional Redis for distributed state

**ThrottleMiddleware**: Rate limiting logic
- **Dynamic limits**: Adjusts based on user behavior patterns
- **Sources**: Redis (distributed) or SQLite (local)
- **Admin bypass**: Configured users skip all limits
- **Snarky replies**: "Пригальмуй, балакучий" when exceeded

### **7. User Profiling System** (`user_profile.py`)

**Tracks**:
- User facts extracted from conversations (preferences, relationships, attributes)
- Interaction counts per chat/thread
- Confidence scores for extracted facts
- Profile summaries for context enrichment

**Fact extraction methods**:
- Rule-based (regex patterns)
- Local LLM (llama.cpp)
- Hybrid (rule-based + LLM fallback)
- Gemini API (fallback option)

### **8. Tools Available to Bot**

1. **search_messages**: Semantic search through chat history
2. **calculator**: Math expressions via `py_expression_eval`
3. **weather**: OpenWeatherMap API integration
4. **currency**: Exchange rate API for conversions
5. **polls**: Create/vote/close polls in chats

### **9. Continuous Monitoring** (`continuous_monitor.py`)

**Phase 1+ features**:
- Processes ALL messages (not just addressed ones)
- Maintains conversation windows per chat/thread
- Async event queue for background processing
- Circuit breaker for failed extraction attempts
- Proactive response capability (Phase 4, currently disabled)

### **10. Resource Management**

**Optimizer** (`resource_optimizer.py`):
- Monitors CPU/memory usage
- Adjusts optimization levels (0-3) based on pressure
- Emergency mode throttles processing at level 3

**Monitor** (`resource_monitor.py`):
- Tracks system resources via `psutil`
- Logs pressure warnings
- Periodic health checks (60s intervals)

---

## **Key Behavioral Rules**

1. **Only respond when addressed**: Via mention, reply, or direct message
2. **Cache all messages**: Even unaddressed ones for context
3. **Rate limit aggressively**: Dynamic quotas, snarky rejections
4. **Clean responses**: Strip all `[meta]` tags and technical IDs
5. **Persist everything**: User + bot turns with embeddings
6. **Background profiling**: Extract facts asynchronously, don't block replies
7. **Admin privileges**: Bypass bans and quotas for configured user IDs
8. **Fallback gracefully**: Error messages are sarcastic, never technical

The bot essentially acts as a conversational AI with memory, personality, and tool access, while maintaining strict rate limits and privacy boundaries.

---

_**User (2025-10-06 06:16Z)**_

What multimodal capabilities does Gemini 2.5 Flash via API have? 

---

_**Assistant (copilot/claude-sonnet-4.5)**_

I'll search for information about Gemini 2.5 Flash's multimodal capabilities via API. 

Based on the official Gemini API documentation, here are **Gemini 2.5 Flash's multimodal capabilities** via API:

## **Input Modalities Supported**

### **1. Text** ✅
- Standard text prompts and conversations
- System instructions
- Long context support (1M+ tokens)

### **2. Images** ✅
**Formats supported:**
- PNG (`image/png`)
- JPEG (`image/jpeg`)
- WEBP (`image/webp`)
- HEIC (`image/heic`)
- HEIF (`image/heif`)

**Capabilities:**
- Image captioning, classification, visual Q&A
- **Object detection** with bounding boxes (coordinates normalized 0-1000)
- **Segmentation** with contour masks (enhanced in 2.5 series)
- Multiple images per prompt (up to 3,600 images)
- Inline data (<20MB total) or Files API for larger/repeated use
- Each image costs 258 tokens if ≤384px, more for larger (tiled at 768x768)

### **3. Audio** ✅
**Formats supported:**
- WAV (`audio/wav`)
- MP3 (`audio/mp3`)
- AIFF (`audio/aiff`)
- AAC (`audio/aac`)
- OGG Vorbis (`audio/ogg`)
- FLAC (`audio/flac`)

**Capabilities:**
- Transcription
- Question answering about audio content
- Understanding non-speech sounds (birdsong, sirens)
- Timestamp references (`MM:SS` format)
- Max 9.5 hours per prompt
- 32 tokens per second of audio
- Downsampled to 16 Kbps mono

### **4. Video** ✅
**Formats supported:**
- MP4 (`video/mp4`)
- MPEG (`video/mpeg`)
- MOV (`video/mov`)
- AVI (`video/avi`)
- FLV (`video/x-flv`)
- MPG (`video/mpg`)
- WebM (`video/webm`)
- WMV (`video/wmv`)
- 3GPP (`video/3gpp`)

**Capabilities:**
- Video summarization, segmentation, information extraction
- Transcription with visual descriptions
- Timestamp references (`MM:SS` format)
- **YouTube URL direct input** (preview feature, up to 8hrs/day free tier)
- Custom frame rate sampling (default 1 FPS)
- Clipping by start/end offsets
- Up to **10 videos per request** (Gemini 2.5+)
- 2M context models: up to 2 hours at default resolution, 6 hours at low resolution
- ~300 tokens/second (default) or ~100 tokens/second (low resolution)

### **5. Documents** ✅
- PDF processing
- Code understanding
- Document analysis with long context

## **Current Bot Implementation Status**

Looking at your code in `media.py` and `gemini.py`:

**✅ Currently supported:**
- Images (photos, stickers via `collect_media_parts`)
- Documents (converted to base64 inline data)

**❌ Not yet implemented:**
- Audio files
- Video files  
- YouTube URLs
- Advanced image features (object detection, segmentation)

## **Potential Enhancements for Your Bot**

You could extend `collect_media_parts` to support:
1. **Voice messages** - Telegram audio → transcription/Q&A
2. **Video notes/files** - Telegram video → summarization
3. **Video links** - YouTube URLs → content understanding
4. **Advanced vision** - Object detection for identifying items in photos

The current implementation already handles the base64 encoding correctly, so adding audio/video would mainly require:
- Detecting additional `message` attributes (`.voice`, `.video`, `.video_note`)
- Mapping Telegram MIME types to Gemini-supported formats
- Handling Files API for >20MB content

---

_**User (2025-10-06 06:17Z)**_

Fix/implement *all* possible multimodal functionality for this bot. Plan it first, then execute.

---

_**Assistant (copilot/claude-sonnet-4.5)**_

I'll plan and implement comprehensive multimodal functionality for the bot. Let me first examine the current media handling implementation and then create a complete solution. 

Now let me check the Gemini client to understand how it handles media: 

Perfect! Now let me create a comprehensive implementation plan and execute it:

## **Implementation Plan**

### **Phase 1: Enhanced Media Collection (`media.py`)**
- 

---

