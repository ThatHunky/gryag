# Chat Analysis Insights & Plan Refinements

**Date**: October 1, 2025  
**Analysis Source**: Real Telegram chat history export  
**Purpose**: Refine continuous learning system based on actual conversation patterns

---

## Observed Conversation Patterns

### 1. Message Characteristics

**High-frequency patterns observed**:
- **Stickers & Media**: ~40% of messages are stickers, photos, videos without text
- **Short reactions**: "üëã", emoticons, single-word responses ("–Ω–æ—Ä–º", "—Ç–∞", "—â–µ")
- **Rapid-fire exchanges**: 10-20 messages per minute during active periods
- **Thread-based discussions**: Topics last 5-15 messages before shifting
- **Casual language**: Heavy use of slang, abbreviations, colloquialisms
- **Code-switching**: Mix of Ukrainian, Russian, English terms
- **Reply chains**: Heavy use of Telegram's reply feature for context

### 2. Valuable Learning Opportunities

**From sample analysis, users reveal**:

**Personal Preferences & Opinions**:
- "–Ø–∫–∞ –∂ —É—î–±–∞–Ω—Å—å–∫–∞ –≥—Ä–∞ —à–∞—Ö–∏" ‚Üí strong opinion about chess (negative)
- "–ú–µ–Ω—ñ –Ω–∞–≤—ñ—Ç—å –ø–æ–ª–æ–≤–∏–Ω–∞ –∑ —Ü—å–æ–≥–æ –Ω–æ—Ä–º" ‚Üí financial expectations/preferences
- Health information discussions (kidney donation topic)
- Risk tolerance: "–•—Ç–æ –Ω–µ —Ä–∏–∑–∏–∫—É—î —Ç–æ–π –Ω–µ –º–∞—î $100–∫"

**Personality Traits**:
- Humor style (sarcastic, self-deprecating)
- Communication patterns (direct, casual)
- Engagement level in different topics
- Reaction to controversy/jokes

**Relationships & Dynamics**:
- Who replies to whom frequently
- Shared jokes and references ("–ª–∞–±—É–±—É")
- Support/criticism patterns
- Group dynamics and roles

**Interests & Topics**:
- Gaming (chess, strategy games)
- Financial topics (money, transactions)
- Health/medical discussions
- Pop culture references
- Technology/products

### 3. Critical Observations for System Design

**Challenges Identified**:
1. **High noise-to-signal ratio**: Most messages are social glue, not fact-rich
2. **Context dependency**: Many messages meaningless without thread context
3. **Ephemeral topics**: Conversations shift rapidly (5-10 min per topic)
4. **Mixed languages**: Need multilingual understanding
5. **Heavy media usage**: Text-only analysis misses significant context

**Opportunities**:
1. **Rich personality data**: Communication style reveals a lot
2. **Relationship graphs**: Clear interaction patterns
3. **Topic expertise**: Users have strong opinions on specific domains
4. **Temporal patterns**: Likely active during specific hours/topics
5. **Sentiment arcs**: Can track mood through conversation flow

---

## Enhanced System Requirements

### 1. Message Classification Refinements

**Update LOW_VALUE_PATTERNS**:

```python
LOW_VALUE_PATTERNS = {
    # Original patterns
    "reactions": ["lol", "haha", "nice", "ok", "+1", "üëç", "üòÇ"],
    "greetings": ["hi", "hello", "bye", "good morning", "gn"],
    
    # NEW: Ukrainian/Russian specific
    "short_reactions_ua": ["—Ç–∞", "–Ω–æ—Ä–º", "–æ–∫", "–Ω—ñ", "—Ç–∞–∫", "–Ω–µ", "–¥–∞"],
    "single_emoji": lambda msg: len(msg.strip()) <= 3 and any(c in emoji_set for c in msg),
    "sticker_only": lambda msg: msg.startswith("[Sticker]") or "Not included" in msg,
    
    # NEW: Very short without context
    "ultra_short": lambda msg: len(msg.split()) == 1 and len(msg) < 5,
    
    # NEW: Pure reactions to media
    "media_reaction": ["üî•", "üëè", "‚ù§Ô∏è", "üòç", "üíÄ"],
}
```

**Add MEDIUM_VALUE_SIGNALS**:

```python
MEDIUM_VALUE_SIGNALS = {
    # Worth analyzing in context, not alone
    "opinion_marker": ["—É—î–±–∞–Ω—Å—å–∫–∞", "–∫—Ä—É—Ç–æ", "–ø–æ–≥–∞–Ω–æ", "—Å—É–ø–µ—Ä", "–∂–∞—Ö"],
    "preference_hint": ["–º–µ–Ω—ñ", "—è", "—Ö–æ—á—É", "–ª—é–±–ª—é", "–Ω–µ–Ω–∞–≤–∏–¥–∂—É"],
    "personal_share": ["—É –º–µ–Ω–µ", "–≤ –º–µ–Ω–µ", "—è –º–∞—é"],
    "question_marker": ["?", "—á–æ–º—É", "—è–∫", "–∫–æ–ª–∏", "—â–æ"],
    "strong_reaction": ["–±–ª—è—Ç—å", "–ø—ñ–∑–¥–∞", "fuck", "shit"],
}
```

**Add HIGH_VALUE_SIGNALS**:

```python
HIGH_VALUE_SIGNALS = {
    # Definitely analyze these
    "explicit_preference": ["–ª—é–±–ª—é", "–Ω–µ–Ω–∞–≤–∏–¥–∂—É", "—É–ª—é–±–ª–µ–Ω–∏–π", "–Ω–∞–π–∫—Ä–∞—â–∏–π"],
    "personal_info": ["–º–µ–Ω—ñ.*—Ä–æ–∫—ñ–≤", "—è.*–∑", "–ø—Ä–∞—Ü—é—é", "–≤—á—É—Å—è"],
    "strong_opinion": ["–Ω–∞–π–≥—ñ—Ä—à", "–Ω–∞–π–∫—Ä–∞—â", "–Ω—ñ–∫–æ–ª–∏", "–∑–∞–≤–∂–¥–∏"],
    "future_intent": ["–±—É–¥—É", "–∑–±–∏—Ä–∞—é—Å—å", "–ø–ª–∞–Ω—É—é", "—Ö–æ—á—É"],
    "experience_share": ["–±—É–≤", "—Ä–æ–±–∏–≤", "–±–∞—á–∏–≤", "–ø—Ä–æ–±—É–≤–∞–≤"],
    "expertise": ["–∑–Ω–∞—é —è–∫", "–º–æ–∂—É", "–≤–º—ñ—é", "—Ä–æ–∑—É–º—ñ—é"],
}
```

### 2. Conversation Window Adjustments

**Refined window parameters based on observed patterns**:

```python
class ConversationWindowConfig:
    # Original: 10 messages, 300 seconds
    # Updated based on observation:
    
    WINDOW_SIZE = 8  # Conversations shift faster than expected
    TIME_WINDOW = 180  # 3 minutes (topics change quickly)
    MIN_MESSAGES = 3  # Need minimum context
    
    # NEW: Topic shift detection
    TOPIC_SHIFT_INDICATORS = [
        "change in participant set (2+ new speakers)",
        "time gap > 60 seconds",
        "shift from reply chains to new thread",
        "language switch (ua ‚Üí en ‚Üí ru)",
        "media type change (text ‚Üí photos ‚Üí videos)",
    ]
    
    # NEW: Active discussion markers
    ACTIVE_DISCUSSION_SIGNALS = [
        "multiple participants (3+)",
        "rapid messages (< 30s between)",
        "reply chains (3+ consecutive replies)",
        "questions and answers",
        "debate markers (–∞–ª–µ, however, but)",
    ]
```

### 3. Multilingual Fact Extraction

**Critical addition: Language-aware extraction**

```python
class MultilingualFactExtractor:
    """Handle Ukrainian, Russian, English mix."""
    
    LANGUAGE_PATTERNS = {
        "ukrainian": ["—è", "–º–µ–Ω—ñ", "–º–µ–Ω–µ", "–º–æ—é", "–≤ –º–µ–Ω–µ", "—É –º–µ–Ω–µ"],
        "russian": ["—è", "–º–Ω–µ", "–º–µ–Ω—è", "–º–æ–π", "—É –º–µ–Ω—è"],
        "english": ["I", "me", "my", "mine", "I have", "I am"],
    }
    
    async def extract_multilingual_facts(self, message: str, context: list) -> list:
        """
        Extract facts accounting for language mixing.
        
        Challenges:
        - Same words in different languages (—è = I in both ua/ru)
        - Code-switching mid-sentence
        - Transliteration (privet, nor–º)
        - Slang that crosses languages
        """
        # Detect primary language
        lang = self._detect_language(message)
        
        # Use language-specific patterns
        patterns = self.PATTERNS[lang]
        
        # Extract using appropriate model
        if self.local_model_supports_language(lang):
            facts = await self.local_model.extract(message, lang, context)
        else:
            facts = await self.rule_based.extract(message, lang, context)
        
        return facts
```

### 4. Context-Aware Fact Validation

**Based on observed context dependency**:

```python
class ContextAwareFacts Validator:
    """Validate facts using conversation context."""
    
    def requires_context(self, fact: Fact) -> bool:
        """Check if fact needs context to be meaningful."""
        
        # These statements need context from thread:
        CONTEXT_DEPENDENT = [
            "references to '—Ü–µ', '—Ç–æ–π', '—Ç–∞', '—Ü–µ' (demonstratives)",
            "comparisons without object ('–∫—Ä–∞—â–µ', '–±—ñ–ª—å—à–µ')",
            "responses to questions",
            "reactions to previous statements",
            "pronouns without antecedents",
        ]
        
        return any(pattern in fact.fact_value for pattern in CONTEXT_DEPENDENT)
    
    async def enrich_with_context(self, fact: Fact, window: ConversationWindow):
        """Add missing context to make fact standalone."""
        
        # Example:
        # Message: "–¢–∞ –Ω–æ—Ä–º –≤ –º–µ–Ω–µ –Ω–∏—Ä–∫–∞"
        # Context: Previous discussion about kidney donation
        # Enriched fact: "Has healthy kidney, open to donation discussion"
        
        if self.requires_context(fact):
            context_summary = await self._summarize_relevant_context(
                fact, window
            )
            fact.evidence_text = f"{context_summary} ‚Üí {fact.evidence_text}"
            fact.needs_context = False
```

### 5. Relationship Graph Extraction

**New module based on observed interaction patterns**:

```python
class RelationshipGraphBuilder:
    """Track user relationships and interaction patterns."""
    
    async def analyze_interaction(
        self,
        window: ConversationWindow
    ) -> list[RelationshipInsight]:
        """
        Extract relationship insights from conversation.
        
        Observable patterns:
        - Who replies to whom (affinity)
        - Reaction usage (who reacts to whom)
        - Topic co-participation
        - Support/agreement patterns
        - Humor/banter patterns
        - Shared references
        """
        
        insights = []
        
        # Reply pattern analysis
        reply_graph = self._build_reply_graph(window)
        for user_a, user_b in reply_graph.edges:
            strength = reply_graph.edge_weight(user_a, user_b)
            insights.append(RelationshipInsight(
                user_a=user_a,
                user_b=user_b,
                type="frequent_interaction",
                strength=strength,
                evidence="replies_to_frequently"
            ))
        
        # Reaction pattern analysis
        reactions = self._analyze_reactions(window)
        for user_a, user_b, emoji in reactions:
            insights.append(RelationshipInsight(
                user_a=user_a,
                user_b=user_b,
                type="appreciates",
                strength=0.6,
                evidence=f"reacts_with_{emoji}"
            ))
        
        # Shared topic participation
        topics = self._identify_topics(window)
        for topic in topics:
            participants = topic.participants
            for i, user_a in enumerate(participants):
                for user_b in participants[i+1:]:
                    insights.append(RelationshipInsight(
                        user_a=user_a,
                        user_b=user_b,
                        type="shared_interest",
                        strength=0.4,
                        evidence=f"both_discuss_{topic.name}"
                    ))
        
        return insights
```

### 6. Media-Aware Context

**Handle heavy media usage**:

```python
class MediaContextManager:
    """Track media context for better understanding."""
    
    async def process_message_with_media(
        self,
        message: Message,
        media_items: list
    ) -> EnrichedMessage:
        """
        Enrich text with media context.
        
        Observed patterns:
        - Photo shared ‚Üí discussion about photo topic
        - Sticker ‚Üí emotional context/reaction
        - Video forward ‚Üí topic introduction
        - Multiple media ‚Üí showcase/sharing behavior
        """
        
        enriched = EnrichedMessage(
            text=message.text or "",
            timestamp=message.date,
            user=message.from_user
        )
        
        if media_items:
            media_context = self._infer_media_context(media_items)
            enriched.inferred_topic = media_context.topic
            enriched.emotional_tone = media_context.emotion
            enriched.intent = media_context.intent
            
            # Add to fact extraction prompt
            enriched.extraction_hint = (
                f"User shared {len(media_items)} media items "
                f"({media_context.types}), suggesting interest in "
                f"{media_context.topic}"
            )
        
        return enriched
```

### 7. Proactive Trigger Refinements

**Based on observed conversation dynamics**:

```python
class RefinedProactiveTrigger:
    """Updated trigger logic based on real patterns."""
    
    def should_interrupt_rapid_exchange(self, window: ConversationWindow) -> bool:
        """
        NEVER interrupt rapid exchanges.
        
        Observed: Users exchange 10-20 messages/minute
        Bot should wait for natural pause (> 60s gap)
        """
        recent_gaps = window.get_message_gaps(last_n=5)
        return all(gap > 60 for gap in recent_gaps)
    
    def detect_help_opportunity(self, window: ConversationWindow) -> Optional[HelpIntent]:
        """
        Detect when bot's knowledge could help.
        
        Real patterns:
        - Factual questions: "–¶—ñ–∫–∞–≤–æ –∑–≤–∏—á–∞–π–Ω–æ —è–∫ —Ü—ñ–Ω–∞ –Ω–∞ —Ç—ñ –ª–∞–±—É–±—É —Å—Ñ–æ—Ä–º—É–≤–∞–ª–∞—Å—å"
        - Technical problems: (chess game frustration)
        - Information requests: implicit curiosity
        """
        
        # Look for:
        # 1. Question markers ("–¶—ñ–∫–∞–≤–æ", "—è–∫", "—á–æ–º—É")
        # 2. Frustration with solvable problems
        # 3. Factual claims that can be verified/expanded
        # 4. Requests for recommendations
        
        for msg in window.messages[-5:]:
            if self._is_curious_question(msg):
                return HelpIntent(
                    type="answer_curiosity",
                    confidence=0.7,
                    trigger_message=msg
                )
            elif self._is_solvable_frustration(msg):
                return HelpIntent(
                    type="offer_solution",
                    confidence=0.6,
                    trigger_message=msg
                )
        
        return None
    
    def respect_banter_mode(self, window: ConversationWindow) -> bool:
        """
        Detect when conversation is just social/banter.
        
        Signals:
        - Jokes, sarcasm
        - Rapid back-and-forth
        - Shared references/inside jokes
        - No serious questions
        
        Bot should NOT interrupt banter unless explicitly mentioned.
        """
        banter_signals = [
            window.has_humor_markers(),
            window.has_inside_references(),
            window.interaction_rate > 5/minute,
            not window.has_serious_questions(),
        ]
        
        return sum(banter_signals) >= 3
```

---

## Updated Implementation Priorities

### Phase 1 Additions (Foundation)

Add to original Phase 1:

1. **Multilingual support infrastructure**
   - Language detection
   - Language-specific pattern matching
   - Transliteration handling

2. **Media context tracking**
   - Media type classification
   - Context inference from media
   - Media-text correlation

3. **Reply chain analysis**
   - Track Telegram reply relationships
   - Build interaction graphs
   - Context propagation through replies

### Phase 2 Additions (Fact Quality)

Add to original Phase 2:

1. **Context enrichment system**
   - Identify context-dependent facts
   - Enrich with conversation context
   - Standalone fact validation

2. **Relationship graph builder**
   - User interaction patterns
   - Affinity scores
   - Shared interest detection

### Phase 3 Additions (Continuous Processing)

Add to original Phase 3:

1. **Rapid-fire message handling**
   - Batching during high-volume periods
   - Adaptive processing rates
   - Queue management under load

2. **Topic shift detection**
   - Conversation segmentation
   - Topic classification
   - Trend identification

### Phase 4 Additions (Proactive Responses)

Add to original Phase 4:

1. **Banter detection**
   - Social vs informational mode
   - Inside joke recognition
   - Appropriate timing

2. **Curiosity-based triggers**
   - Question detection (even implicit)
   - Knowledge gap identification
   - Appropriate information offering

---

## Specific Pattern Matching Examples

### Ukrainian/Russian Fact Patterns

```python
FACT_PATTERNS_UA_RU = {
    # Personal preferences
    "likes": [
        r"(–ª—é–±–ª—é|–Ω—Ä–∞–≤–∏—Ç—Å—è|like)\s+(.+)",
        r"(.+)\s+(–∫—Ä—É—Ç|—Å—É–ø–µ—Ä|—á—É–¥–æ–≤|awesome)",
        r"–º–µ–Ω—ñ –ø–æ–¥–æ–±–∞—î—Ç—å—Å—è\s+(.+)",
    ],
    
    "dislikes": [
        r"(–Ω–µ–Ω–∞–≤–∏–¥–∂—É|–Ω–µ –ª—é–±–ª—é|hate)\s+(.+)",
        r"(.+)\s+(—É—î–±–∞–Ω—Å—å–∫|–ø–æ–≥–∞–Ω–æ|shit|terrible)",
        r"—è–∫–∏–π –∂–µ\s+(.+)\s+(–ø–æ–≥–∞–Ω|–¥—É—Ä–Ω)",
    ],
    
    # Opinions
    "opinion": [
        r"—è –¥—É–º–∞—é —â–æ\s+(.+)",
        r"–Ω–∞ –º–æ—é –¥—É–º–∫—É\s+(.+)",
        r"(.+)\s+(–Ω–∞–π–∫—Ä–∞—â|–Ω–∞–π–≥—ñ—Ä—à|best|worst)",
    ],
    
    # Personal info
    "has": [
        r"(—É –º–µ–Ω–µ|–≤ –º–µ–Ω–µ|—è –º–∞—é)\s+(.+)",
        r"–º—ñ–π\s+(.+)",
        r"–º–æ—è\s+(.+)",
    ],
    
    # Future intent
    "wants": [
        r"(—Ö–æ—á—É|—Ö–æ—Ç—ñ–≤ –±–∏|would like)\s+(.+)",
        r"(–∑–±–∏—Ä–∞—é—Å—å|–ø–ª–∞–Ω—É—é|planning)\s+(.+)",
        r"–º–µ–Ω—ñ\s+(—Ç—Ä–µ–±–∞|–ø–æ—Ç—Ä—ñ–±–Ω–æ|need)\s+(.+)",
    ],
}
```

### Conversation State Patterns

```python
CONVERSATION_STATES = {
    "banter": {
        "indicators": ["üòÇ", "lol", "—Ö–∞", "jokes", "sarcasm"],
        "pace": "rapid (>3 msg/min)",
        "style": "casual",
        "bot_action": "observe_only",
    },
    
    "discussion": {
        "indicators": ["–ø–∏—Ç–∞–Ω–Ω—è", "—á–æ–º—É", "—è–∫", "–¥—É–º–∞—î—à"],
        "pace": "moderate (1-3 msg/min)",
        "style": "thoughtful",
        "bot_action": "consider_joining",
    },
    
    "problem_solving": {
        "indicators": ["—è–∫ –∑—Ä–æ–±–∏—Ç–∏", "–ø—Ä–æ–±–ª–µ–º–∞", "–Ω–µ –ø—Ä–∞—Ü—é—î", "help"],
        "pace": "any",
        "style": "focused",
        "bot_action": "offer_help_high_priority",
    },
    
    "info_sharing": {
        "indicators": ["–¥–∏–≤–∏—Å—å", "–±–∞—á–∏–≤", "—Ü—ñ–∫–∞–≤–æ", "interesting"],
        "pace": "moderate",
        "style": "informative",
        "bot_action": "add_context_if_relevant",
    },
}
```

---

## Testing with Real Data

### Test Cases from Actual Chat

1. **Short reaction chain** (should skip):
   ```
   User1: [Photo]
   User2: "üëç"
   User3: "–Ω–æ—Ä–º"
   User4: "üî•"
   ‚Üí Classification: SKIP (all low-value reactions)
   ```

2. **Opinion expression** (should analyze):
   ```
   User1: "–Ø–∫–∞ –∂ —É—î–±–∞–Ω—Å—å–∫–∞ –≥—Ä–∞ —à–∞—Ö–∏"
   ‚Üí Classification: ANALYZE_NOW (strong opinion)
   ‚Üí Extract: Fact(type="opinion", key="chess", value="dislikes chess (strong)", confidence=0.9)
   ```

3. **Context-dependent exchange** (needs thread analysis):
   ```
   User1: "–ê —è–∫—â–æ —è –ø—Ä–∏–Ω–µ—Å—É 65–∫–≥?"
   User2: "–ß–∏ —Ç–æ 61"
   User1: "–ù—É 60-65–∫–≥"
   ‚Üí Classification: ANALYZE_LATER (needs context from previous discussion about kidney donation)
   ‚Üí Window analysis reveals topic
   ‚Üí Extract: Fact(type="personal", key="weight", value="60-65kg", confidence=0.7)
   ```

4. **Curiosity trigger** (proactive opportunity):
   ```
   User1: "–¶—ñ–∫–∞–≤–æ –∑–≤–∏—á–∞–π–Ω–æ —è–∫ —Ü—ñ–Ω–∞ –Ω–∞ —Ç—ñ –ª–∞–±—É–±—É —Å—Ñ–æ—Ä–º—É–≤–∞–ª–∞—Å—å"
   ‚Üí Classification: ANALYZE_NOW
   ‚Üí Intent: curiosity about pricing
   ‚Üí Proactive trigger: IF bot has knowledge about viral toy pricing ‚Üí CONSIDER_RESPONSE
   ```

5. **Rapid banter** (should not interrupt):
   ```
   [12 messages in 2 minutes, jokes, inside references]
   ‚Üí State: BANTER_MODE
   ‚Üí Proactive: NO_RESPONSE (wait for pause or explicit mention)
   ```

---

## Key Takeaways for Implementation

### DO:
1. ‚úÖ **Prioritize conversation windows** over individual messages
2. ‚úÖ **Detect and respect banter mode** - don't interrupt fun
3. ‚úÖ **Handle multilingual content** from the start
4. ‚úÖ **Track relationships** between users (valuable data)
5. ‚úÖ **Use reply chains** for context propagation
6. ‚úÖ **Wait for natural pauses** before responding proactively
7. ‚úÖ **Enrich context-dependent facts** before storage

### DON'T:
1. ‚ùå **Don't process every message** - filtering is critical
2. ‚ùå **Don't interrupt rapid exchanges** - respect conversation flow
3. ‚ùå **Don't analyze stickers/reactions alone** - low value
4. ‚ùå **Don't ignore media context** - significant indicator
5. ‚ùå **Don't assume language** - detect and adapt
6. ‚ùå **Don't store orphan facts** - always link to context
7. ‚ùå **Don't be pushy** - conservative proactive triggers

---

## Metrics Specific to This Chat Pattern

```python
EXPECTED_METRICS = {
    # Message classification
    "skip_rate": 0.45,  # 45% stickers, short reactions, media-only
    "analyze_rate": 0.25,  # 25% worth extracting facts from
    "cache_only_rate": 0.30,  # 30% useful as context only
    
    # Conversation windows
    "avg_window_size": 6.5,  # Messages per analysis window
    "avg_window_duration": 180,  # 3 minutes (topics shift quickly)
    "topic_shifts_per_hour": 15,  # Very dynamic conversation
    
    # Fact extraction
    "facts_per_analyzed_message": 0.3,  # Not every message has facts
    "context_dependent_facts": 0.4,  # 40% need context enrichment
    "multilingual_messages": 0.2,  # 20% mix languages
    
    # Proactive responses
    "banter_mode_time": 0.6,  # 60% of time is social/banter
    "appropriate_response_opportunities": 0.05,  # 5% of windows
    "successful_proactive_rate": 0.7,  # 70% should be well-received
}
```

---

## Conclusion

Real chat analysis reveals that the continuous learning system must be:

1. **Highly selective**: Most messages are noise, filter aggressively
2. **Context-aware**: Facts mean nothing without conversation context
3. **Culturally adaptive**: Multilingual, slang-aware, meme-literate
4. **Socially intelligent**: Distinguish banter from serious discussion
5. **Relationship-aware**: Track who talks to whom, how, and why
6. **Media-conscious**: Don't ignore non-text content
7. **Timing-sensitive**: Never interrupt the flow

The system should feel like a lurker who occasionally chimes in with helpful insights, not an eager participant who responds to everything. Quality over quantity for both learning and engagement.

---

**Next Steps**: Incorporate these refinements into main implementation plan, especially:
- Multilingual fact extraction patterns
- Banter detection logic
- Context enrichment system
- Relationship graph tracking
- Conservative proactive triggers

**Document Version**: 1.0  
**Last Updated**: October 1, 2025  
**Based On**: Real Telegram chat export analysis
